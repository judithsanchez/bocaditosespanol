import {errors} from 'utils/lib/constans';
import {tokenizeSentences} from '../tokenizeSentences';

describe('tokenizeSentences', () => {
	test('tokenizes a simple sentence correctly', () => {
		const sentence = 'Hello, world!';
		const expected = {
			sentence: sentence,
			tokens: ['Hello', ',', 'world', '!'],
		};
		const result = tokenizeSentences(sentence);
		expect(result).toEqual(expected);
	});

	test('tokenizes a sentence with multiple punctuation marks correctly', () => {
		const sentence = 'Hello, world! How are you?';
		const expected = {
			sentence: sentence,
			tokens: ['Hello', ',', 'world', '!', 'How', 'are', 'you', '?'],
		};
		const result = tokenizeSentences(sentence);
		expect(result).toEqual(expected);
	});

	test('tokenizes a sentence with emojis correctly', () => {
		const sentence = 'Hello ðŸ‘‹ðŸ», world! ðŸ˜€';
		const expected = {
			sentence: sentence,
			tokens: ['Hello', 'ðŸ‘‹ðŸ»', ',', 'world', '!', 'ðŸ˜€'],
		};
		const result = tokenizeSentences(sentence);
		expect(result).toEqual(expected);
	});

	test('tokenizes a sentence with ellipsis correctly', () => {
		const sentence = 'Hello... world!';
		const expected = {
			sentence: sentence,
			tokens: ['Hello', '...', 'world', '!'],
		};
		const result = tokenizeSentences(sentence);
		expect(result).toEqual(expected);
	});

	test('handles emojis with skin tone modifiers', () => {
		const sentence = 'ðŸ‘‹ðŸ» ðŸ‘‹ðŸ¼ ðŸ‘‹ðŸ½ ðŸ‘‹ðŸ¾ ðŸ‘‹ðŸ¿';
		const expected = {
			sentence: sentence,
			tokens: ['ðŸ‘‹ðŸ»', 'ðŸ‘‹ðŸ¼', 'ðŸ‘‹ðŸ½', 'ðŸ‘‹ðŸ¾', 'ðŸ‘‹ðŸ¿'],
		};
		const result = tokenizeSentences(sentence);
		expect(result).toEqual(expected);
	});

	test('handles emojis with gender modifiers', () => {
		const sentence = 'ðŸ‘¨â€ðŸ’» ðŸ‘©â€ðŸ’»';
		const expected = {
			sentence: sentence,
			tokens: ['ðŸ‘¨â€ðŸ’»', 'ðŸ‘©â€ðŸ’»'],
		};
		const result = tokenizeSentences(sentence);
		expect(result).toEqual(expected);
	});

	test('handles emojis with multiple modifiers', () => {
		const sentence = 'ðŸ‘©ðŸ½â€ðŸ’» ðŸ‘¨ðŸ¼â€ðŸ³';
		const expected = {
			sentence: sentence,
			tokens: ['ðŸ‘©ðŸ½â€ðŸ’»', 'ðŸ‘¨ðŸ¼â€ðŸ³'],
		};
		const result = tokenizeSentences(sentence);
		expect(result).toEqual(expected);
	});

	test('handles emojis with and without modifiers', () => {
		const sentence = 'ðŸ‘‹ðŸ» ðŸ‘‹ ðŸ‘©ðŸ½â€ðŸ’» ðŸ‘¨â€ðŸ³';
		const expected = {
			sentence: sentence,
			tokens: ['ðŸ‘‹ðŸ»', 'ðŸ‘‹', 'ðŸ‘©ðŸ½â€ðŸ’»', 'ðŸ‘¨â€ðŸ³'],
		};
		const result = tokenizeSentences(sentence);
		expect(result).toEqual(expected);
	});
	test('throws an error when input is not a string', () => {
		expect(() => tokenizeSentences(123 as unknown as string)).toThrow(
			errors.mustBeString,
		);
		expect(() => tokenizeSentences(undefined as unknown as string)).toThrow(
			errors.mustBeString,
		);
		expect(() => tokenizeSentences(false as unknown as string)).toThrow(
			errors.mustBeString,
		);
	});
	test('throws an error for an empty string', () => {
		const sentence = '';
		expect(() => tokenizeSentences(sentence)).toThrow(
			'Cannot tokenize an empty sentence',
		);
	});
});
